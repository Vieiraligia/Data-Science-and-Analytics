üöÄ **MVP 1 ‚Äî Engenharia de Dados**

Este primeiro MVP est√° associado √† disciplina de Engenharia de Dados. <br>

A proposta √© desenvolver um pipeline de dados aplicando boas pr√°ticas de engenharia de dados e utilizando os
recursos do ecossistema  [Databricks](https://databricks.com) que √© uma plataforma unificada para an√°lise de dados. <br> 
<br>O pipeline deve contemplar as seguintes etapas:
<br><br>

üì• Coleta / ingest√£o<br>
üß± Modelagem<br>
üì¶ Carga dos dados processados<br>
üìä An√°lise explorat√≥ria e valida√ß√£o<br>
<br>


## Objetivo

Este MVP aborda o tema ciberseguran√ßa, com foco em viola√ß√£o de dados. A partir das an√°lises realizadas, busca-se identificar percep√ß√µes sobre a seguran√ßa cibern√©tica e entender quais tipos de empresas s√£o mais vulner√°veis.

O principal objetivo √© identificar tend√™ncias e padr√µes relacionados ao aumento dos ataques de viola√ß√£o de dados, respondendo √†s seguintes quest√µes: 
 
1.	Quais s√£o os tipos de ataques mais comuns?
2.	Por que os ataques √†s empresas est√£o aumentando?
3.	Quais tipos de empresas s√£o mais visadas de ataques?
4.	Para cada tipo de ataque, qual √© a forma mais eficiente de preven√ß√£o?
5.	As an√°lises permitem prever cen√°rios futuros de seguran√ßa cibern√©tica? Quais s√£o as perspectivas?

Ao concluir este projeto, espera-se que as an√°lises ofere√ßam insights confi√°veis sobre as tend√™ncias em seguran√ßa cibern√©tica, apoiando a√ß√µes de preven√ß√£o e a elabora√ß√£o de planos de resposta a poss√≠veis incidentes de viola√ß√£o de dados.

## Coleta

Os dados utilizados foram extra√≠dos de fontes p√∫blicas e governamentais obtidos por meio do site [Opendatabay](https://www.opendatabay.com/data/government/45f61e06-1d21-44f5-a159-92d4ae086f65). Esse Dataset tamb√©m encontra-se dispon√≠vel no compilado de datasets da [Kaggle](https://www.kaggle.com/datasets/thedevastator/data-breaches-a-comprehensive-list).

O conjunto de dados re√∫ne informa√ß√µes sobre viola√ß√µes de seguran√ßa cibern√©tica envolvendo incidentes com mais de 30.000 registros. Os anos de 2011 e 2020 se destacam como os per√≠odos com maior n√∫mero de ocorr√™ncias registradas.

Arquivo utilizado: 

- [Dados brutos](https://github.com/Vieiraligia/Data-Science-and-Analytics/blob/main/MVP%20Engenharia%20de%20Dados/bronze_cyber_breaches.csv)

 <br><br>

## Modelagem

Para a constru√ß√£o do pipeline de dados foi escolhido o modelo Medallion Architecture. Essa arquitetura foi desenvolvida pela pr√≥pria Databricks para padronizar a organiza√ß√£o dos dados no Data Lakehouse. 

 - A camada Bronze apresenta os dados 'crus'
 - A camada Silver apresenta dados limpos e refinados
 - A camada Gold apresenta dados prontos para an√°lises, BI e machine learning

Ou seja, cada camada acrescenta um n√≠vel de qualidade dos dados.

#### Camada Bronze 

Os dados deste arquivo foram armazenados exatamente no formato original, sem qualquer altera√ß√£o ou pr√©-processamento.
O conjunto re√∫ne informa√ß√µes p√∫blicas sobre incidentes de viola√ß√£o de dados, abrangendo empresas de diversos setores. Entre os principais dados registrados est√£o: quantidade de registros comprometidos, ano do incidente e m√©todo utilizado no ataque.

Com o carregamento do arquivo RAW - bronze_cyber_breaches.csv, a tabela Bronze reflete exatamente as colunas do arquivo CSV:

| Coluna               | Descri√ß√£o |<br>
| entity               | Empresa ou organiza√ß√£o afetada pelo incidente de ciberseguran√ßa |<br>
| year                 | Ano do incidente |<br>
| records              | Quantidade de registros expostos ou comprometidos |<br>
| organization_type    | Tipo da organiza√ß√£o (ex.: Government, Healthcare, etc.)|<br>
| method               | M√©todo do ataque (ex.: Hacking, Insider, Loss, etc.) |<br>
| sources              | Fonte de onde a informa√ß√£o foi obtida |<br>
| Unnamed: 0           | Coluna t√©cnica presente no arquivo original |<br><br>


<img width="1357" height="610" alt="image" src="https://github.com/user-attachments/assets/9ad25c4c-05e9-4353-8132-8790f3c2b009" />
<p align="center"><em>Camada Bronze - Estrutura do Catalog</em></p>
<br><br><br>

Evid√™ncia de valida√ß√£o <br><br>
<img width="1360" height="610" alt="image" src="https://github.com/user-attachments/assets/38693b1e-3d33-4804-b0fd-0824ab6d4a1c" />
<p align="center"><em>Camada Bronze - Estrutura do Workspace</em></p>
<br><br>

#### Camada Silver
A partir da ingest√£o dos dados por meio da camada Bronze, os dados passaram por processos espec√≠ficos de limpeza, valida√ß√£o e padroniza√ß√£o. Com isso, os dados est√£o consistentes para uso.

Ao realizar uma consulta com a descri√ß√£o da tabela da Camada Bronze foi retornado esses dados


<img width="1345" height="608" alt="image" src="https://github.com/user-attachments/assets/1002c1ae-1ca9-4ad4-9d15-c4e358d7f5df" />
<p align="center"><em>Camada Bronze - Consulta da Descri√ß√£o da tabela</em></p>


Conserto de Tipagem - Exemplos: <br> 
_c0 ‚Üí breach_id (INT)<br>
_c3 ‚Üí year (INT)<br>
_c4 ‚Üí records_exposed (BIGINT)<br>
Com TRY_CAST, para evitar erros de dados sujos.<br>
<br><br>
Limpeza e Padroniza√ß√£o - Exemplos:<br>
TRIM ‚Üí remove espa√ßos extras<br>
INITCAP ‚Üí primeira letra mai√∫scula (Industry, Breach Method)<br>
REGEXP_REPLACE('[^0-9]', '') ‚Üí remove letras e s√≠mbolos<br>
<br>
Inclus√£o do Metadados<br>
Exclus√£o do primeiro registro, pois foi inserido o header<br>
<br><br><br>


Consulta da tabela ajustada<br><br>
<img width="1358" height="611" alt="image" src="https://github.com/user-attachments/assets/aa18716f-7a2e-47ba-a87d-07ed37d47c6b" />
<p align="center"><em>Camada Silver - Consulta da tabela I</em></p>

Visualiza√ß√£o do metadados<br><br>
<img width="1361" height="609" alt="image" src="https://github.com/user-attachments/assets/8560f3dd-bc10-49c0-b1a4-d549234bccba" />
<p align="center"><em>Camada Silver - Consulta da tabela II</em></p>



#### Camada Gold


 
## Carga dos dados processados


## An√°lise e valida√ß√£o
